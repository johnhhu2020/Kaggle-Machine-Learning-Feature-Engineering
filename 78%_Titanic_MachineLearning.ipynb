{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nutritional-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "###reference:\n",
    "    ###https://towardsdatascience.com/machine-learning-with-the-titanic-dataset-7f6909e58280\n",
    "\n",
    "\n",
    "\n",
    "def concat_df(train_data,test_data):\n",
    "    return pd.concat([train_data,test_data],sort=True).reset_index(drop=True)\n",
    "\n",
    "def divide_df(all_data):\n",
    "    return all_data.loc[:890],all_data.loc[891:].drop(['Survived'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data=pd.read_csv(\"train.csv\")\n",
    "test_data=pd.read_csv(\"test.csv\")\n",
    "\n",
    "#df_all=concat_df(train_data,test_data)\n",
    "\n",
    "###JHU not necessary code\n",
    "###dfs=[train_data,test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_data_contains: \"+str(len(train_data))+\" row and \"+str(len(train_data.columns))+\" columns\")\n",
    "print(\"test_data_contains: \"+str(len(test_data))+\" row and \"+str(len(test_data.columns))+\" columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"first_3_row_of_train_data\")\n",
    "display(train_data.head(3))\n",
    "print(\"first_3_row_of_test_data\")\n",
    "display(test_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing_values_in_train_data\")\n",
    "display(train_data.isnull().sum())\n",
    "print(\"missing_value_in_test_data\")\n",
    "display(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=concat_df(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "####2 data cleansing Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing_age_values_in_total_data_set: \"+str(df_all['Age'].isnull().sum()))\n",
    "print(\"missing_percentage: \"+str(round(df_all['Age'].isnull().sum()/len(df_all)*100.0))+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JHU\n",
    "import seaborn as sb\n",
    "\n",
    "train_data['Age'].plot.hist(alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JHU\n",
    "train_data.pivot(columns='Pclass').Age.plot(kind='hist',stacked=True,alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JHU\n",
    "train_data.groupby(['Pclass'])['Age'].plot.hist(alpha=0.4,legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JHU\n",
    "\n",
    "sb.histplot(data=train_data,x=\"Age\",hue=\"Pclass\",multiple=\"stack\",alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('median_for_Age_seperated_by_Pclass:')\n",
    "display(train_data.groupby('Pclass')['Age'].median())\n",
    "print('median_for_Age_seperated_by_Pclass_and_Sex:')\n",
    "display(train_data.groupby(['Pclass','Sex'])['Age'].median())\n",
    "print('bumber_of_cases:')\n",
    "display(train_data.groupby(['Pclass','Sex'])['Age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the missing value with the medians of each group\n",
    "df_all['Age']=df_all.groupby(['Pclass','Sex'])['Age'].apply(lambda x:x.fillna(x.median()))\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "####2 data cleansing Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[df_all['Fare'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc cases which are similiar to Mr.Thomas and use the median of fare to replace the missing for his data set\n",
    "mr_thomas=df_all.loc[(df_all['Pclass']==3)&(df_all['SibSp']==0)&(df_all['Embarked']=='S')]['Fare'].median()\n",
    "print(mr_thomas)\n",
    "df_all.loc[df_all['Fare'].isnull(),'Fare']=mr_thomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "####2 data cleansing Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_data['Cabin'].unique())\n",
    "print('there_are '+str(train_data['Cabin'].nunique())+' different_values_for_Cabin_and '+str(train_data['Cabin'].isnull().sum())+' cases_are_missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep all first letters of Cabin in new variable and use \"M\" for each missing\n",
    "df_all['Deck']=df_all['Cabin'].apply(lambda s:s[0] if pd.notnull(s) else 'M')\n",
    "\n",
    "print(df_all['Deck'].sample(10))\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "df_all[['Deck','Survived']].groupby('Deck')['Survived'].mean().plot(kind='bar')\n",
    "pl.suptitle('Survival_rates_for_different_cabines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JHU\n",
    "\n",
    "df_all.groupby('Deck')['Survived'].mean().plot(kind='bar',alpha=0.4,legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=df_all[df_all['Deck']=='T'].index\n",
    "df_all.loc[idx,'Deck']='A'\n",
    "\n",
    "###JHU i think the upper two lines are not necessary\n",
    "\n",
    "df_all['Deck']=df_all['Deck'].replace(['A','B','C'],'ABC')\n",
    "df_all['Deck']=df_all['Deck'].replace(['D','E'],'DE')\n",
    "df_all['Deck']=df_all['Deck'].replace(['F','G'],'FG')\n",
    "\n",
    "df_all['Deck'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "####2 data cleansing Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[df_all['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for passengers who were in passenger class 1, on deck abc and paid 80 or less for the tickets\n",
    "df_all.loc[(df_all['Pclass']==1)&(df_all['Fare']<=80)&(df_all['Deck']=='ABC')]['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[df_all['Embarked'].isnull(),'Embarked']='S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "####2 data cleansing Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing_in_all_data\")\n",
    "display(df_all.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing_in_train_data\")\n",
    "display(train_data.isnull().sum())\n",
    "\n",
    "###JHU why still keeps null Age values in train_data, since we have replaced\n",
    "###median Age value by Pclass and Sex in df_all???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "####3 feature engineering Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.boxplot(column=['Fare'])###,figsize=(15,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JHU\n",
    "\n",
    "sb.histplot(data=df_all,x=\"Fare\",alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.boxplot(column=['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JHU\n",
    "\n",
    "sb.histplot(data=df_all,x=\"Age\",alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Benedikt Droste\n",
    "###As you can see, there are outliers for both Age and Fare. \n",
    "###The range of values is much higher for Fare compared to Age.\n",
    "###We will cut the istribution into pieces so that the outliers do not \n",
    "###irritate our algorithm. For Fare we will assign the same number of cases \n",
    "###to each category and for Age we will build the categories based on the\n",
    "###values of the variable. This is also the difference between .cut and .qcut.\n",
    "###With .cut, the bins are formed based on the values of the variable, \n",
    "###regardless of how many cases fall into a category. With .qcut we decompose \n",
    "###a distribution so that there are the same number of cases in each category.\n",
    "\n",
    "###JHU ??? it could be the salling strategy which caused the Fare distribution\n",
    "###JHU ??? they plaaned to sell ticket at all price range to cover the cost \n",
    "###JHU ??? but the market demand was not as they expected, so they sell low \n",
    "###JHU ??? priced ticket to young people in last minutes.\n",
    "\n",
    "###df_all['Fare']=pd.qcut(df_all['Fare'],5)#### we must run this first to get\n",
    "###the labels range then use labels parameter to distribute the bins\n",
    "\n",
    "###JHU\n",
    "df_all['Fare']=pd.qcut(df_all['Fare'],5,labels=[\"<7.8\",\"<10.5\",\"<21.5\",\"<41.5\",\"<512.3\"])\n",
    "\n",
    "###JHU\n",
    "df_all['Age']=pd.cut(df_all['Age'],5,labels=[\"<16\",\"<32\",\"<48\",\"<64\",\"<80\"])\n",
    "\n",
    "print(\"For_Age,_each_category_has_a_different_number_of_cases:\")\n",
    "df_all['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For_Fare,_each_category_has_nearly_a_same_number_of_cases:\")\n",
    "df_all['Fare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JHU\n",
    "df_all[['Age','Survived']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['Age','Survived']].groupby('Age')['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['Fare','Survived']].groupby('Fare')['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['Age','Survived']].groupby('Age')['Survived'].mean().plot(kind='bar',alpha=0.4)\n",
    "pl.suptitle('Survival_rates_for_Age_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['Fare','Survived']].groupby('Fare')['Survived'].mean().plot(kind='bar',alpha=0.4)\n",
    "pl.suptitle('Survivel_rate_for_Fare_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "####3 Creat new features out of existing variables Family Size\n",
    "\n",
    "###JHU why we do it this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Family_size']=df_all['SibSp']+df_all['Parch']+1\n",
    "df_all['Family_size'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Family_size_bin']=df_all['Family_size'].map(lambda s:1 if s==1 else(2 if s==2 else(3 if 3<=s<=4 else(4 if s>=5 else 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Family_size_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['Family_size_bin','Survived']].groupby('Family_size_bin')['Survived'].mean().plot(kind='bar',alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "####3 Creat new features out of existing variables Tickets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Ticket_frequency']=df_all.groupby('Ticket')['Ticket'].transform('count')\n",
    "\n",
    "\n",
    "###JHU .transform('count') and what why 'count'\n",
    "###so 1 means most ticket sold category or something??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['Ticket_frequency','Survived']].groupby('Ticket_frequency').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['Ticket_frequency','Survived']].groupby('Ticket_frequency')['Survived'].mean().plot(kind='bar',alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "####3 Creat new features out of existing variables Title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JHU\n",
    "\n",
    "df_all.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Title']=df_all['Name'].str.split(', ',expand=True)[1].str.split('.',expand=True)[0]\n",
    "df_all['Is_married']=0\n",
    "df_all['Is_married'].loc[df_all['Title']=='Mrs']=1\n",
    "\n",
    "\n",
    "###JHU is that a joke or something? it seems many codes are reduandant or just\n",
    "###JHU be there to help the reader learning to code in a proper way??\n",
    "\n",
    "df_all['Title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JHU\n",
    "\n",
    "df_all['Title'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_names=(df_all['Title'].value_counts()<10)\n",
    "\n",
    "df_all['Title']=df_all['Title'].apply(lambda x:'Mice' if title_names.loc[x]==True else x)\n",
    "\n",
    "df_all.groupby('Title')['Title'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JHU\n",
    "df_all[['Title','Survived']].groupby('Title')['Survived'].mean().plot(kind='bar',alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "####3 Creat new features out of existing variables Survival Rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def extract_surname(data):\n",
    "    families=[]\n",
    "    for i in range(len(data)):\n",
    "        name=data.iloc[i]\n",
    "        if '(' in name:\n",
    "            name_no_bracket=name.split('(')[0]\n",
    "        else:\n",
    "            name_no_bracket=name\n",
    "        family=name_no_bracket.split(',')[0]\n",
    "        title=name_no_bracket.split(',')[1].strip().split(' ')[0]\n",
    "        for c in string.punctuation:\n",
    "            family=family.replace(c,'').strip()\n",
    "        families.append(family)\n",
    "    return families\n",
    "\n",
    "df_all['Family']=extract_surname(df_all['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Family'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['Title','Survived','Family_size']].groupby('Title').mean()\n",
    "\n",
    "###JHU THINK & PRACTICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Survival_rates_grouped_by_families_of_women_in_dataset:\")\n",
    "df_all.loc[(df_all['Sex']=='female')&(df_all['Family_size']>1)].groupby('Family')['Survived'].mean().plot.hist(alpha=0.4)\n",
    "\n",
    "###JHU how to read this chart, 0 to 1 on x axes and 0 to 100 on y axes???\n",
    "###JHU and whats the point doing this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_families=df_all[df_all['Title']=='Master']['Family'].tolist()\n",
    "df_all.loc[df_all['Family'].isin(master_families)].groupby('Family')['Survived'].mean().plot.hist(alpha=0.4)\n",
    "\n",
    "###JHU how to read this chart, 0 to 1 on x axes and 0 to 100 on y axes???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create variables with the survival rate of the women and masters\n",
    "\n",
    "women_rate=df_all.loc[(df_all['Sex']=='female')&(df_all['Family_size']>1)].groupby('Family')['Survived'].mean()\n",
    "master_rate=df_all.loc[df_all['Family'].isin(master_families)].groupby('Family')['Survived'].mean()\n",
    "\n",
    "#Combine two series\n",
    "combined_rate=women_rate.append(master_rate)\n",
    "\n",
    "#It is posible that a woman has the family as a master and vice versa, so duplicates have to been dropped\n",
    "combined_rate_df=combined_rate.to_frame().reset_index().rename(columns={'Survived':'Survival_quota'}).drop_duplicates(subset='Family')\n",
    "\n",
    "#Merge the new dataframe\n",
    "df_all=pd.merge(df_all,combined_rate_df,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have calculated a survival rate for only a part of the cases, the others \n",
    "#we set to 0 in the dummy variable\n",
    "\n",
    "df_all['Survival_quota_NA']=1\n",
    "df_all.loc[df_all['Survival_quota'].isnull(),'Survival_quota_NA']=0\n",
    "df_all['Survival_quota']=df_all['Survival_quota'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "####3.3 Label and One Hot Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JHU\n",
    "from sklearn import preprocessing\n",
    "\n",
    "non_numeric_features=['Embarked','Sex','Title','Age','Fare','Deck']\n",
    "\n",
    "for feature in non_numeric_features:\n",
    "    df_all[feature]=preprocessing.LabelEncoder().fit_transform(df_all[feature])\n",
    "    \n",
    "cat_features=['Pclass','Sex','Embarked','Title','Deck','Family_size_bin','Age','Fare']\n",
    "    \n",
    "encoded_features=[]\n",
    "\n",
    "for feature in cat_features:\n",
    "    encoded_feat=preprocessing.OneHotEncoder().fit_transform(df_all[feature].values.reshape(-1,1)).toarray()\n",
    "    n=df_all[feature].nunique()\n",
    "    cols=['{}_{}'.format(feature,n) for n in range(1,n+1)]\n",
    "    encoded_df=pd.DataFrame(encoded_feat,columns=cols)\n",
    "    encoded_df.index=df_all.index\n",
    "    encoded_features.append(encoded_df)\n",
    "\n",
    "\n",
    "df_all=pd.concat([df_all,*encoded_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test=divide_df(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Modeling and prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defined columns which can be dropped for the modeling part because we \n",
    "#created new lable and one hot encoded variants out of them\n",
    "\n",
    "drop_cols=['Embarked','Family','Family_size','Survived','Family_size_bin',\n",
    "           'Deck','Age','Name','Parch','PassengerId','Pclass','Sex','SibSp',\n",
    "           'Title','Ticket','Cabin']\n",
    "\n",
    "drop_cols_2=['Embarked','Family','Family_size','Family_size_bin','Deck','Fare',\n",
    "            'Name','Parch','PassengerId','Pclass','Sex','SibSp','Title',\n",
    "             'Ticket','Cabin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up a random forest classifier\n",
    "#standardization of variables\n",
    "\n",
    "###JHU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "###JHU from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x=preprocessing.StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
    "y=df_train['Survived'].values\n",
    "\n",
    "x_test=preprocessing.StandardScaler().fit_transform(df_test.drop(columns=drop_cols_2))\n",
    "\n",
    "#creating train, test splits\n",
    "x_train,x_test1,y_train,y_test1=train_test_split(x,y,test_size=0.25,random_state=42)\n",
    "\n",
    "#defining model parameters\n",
    "model=RandomForestClassifier(criterion='gini',\n",
    "                                          n_estimators=1750,\n",
    "                                          max_depth=7,\n",
    "                                          min_samples_split=6,\n",
    "                                          min_samples_leaf=6,\n",
    "                                          max_features=True,\n",
    "                                          oob_score=True,\n",
    "                                          random_state=42,\n",
    "                                          n_jobs=-1,\n",
    "                                          verbose=1)\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "predictions=model.predict(x_test)\n",
    "print(model.score(x_test1,y_test1))\n",
    "output=pd.DataFrame({'PassengerId':test_data.PassengerId,'Survived':predictions})\n",
    "output['Survived']=output['Survived'].astype(int)\n",
    "output.to_csv('2020_00_09_titanic_jjj.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-walker",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
